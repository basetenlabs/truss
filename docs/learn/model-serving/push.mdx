---
title: "Step 1: Spin up a model server"
description: "Configure a remote host and push the base Truss"
---

This is the first of three steps dedicated to learning the developer loop that Truss enables. We hope that once you try it, you'll agree with us that it's the most productive way to deploy ML models.

<Accordion title="Configure your remote host" defaultOpen="true">
If this is your first time running `truss push`, you'll need to configure a remote host for your model server.

Truss is maintained by [Baseten](https://baseten.co), which provides infrastructure for running ML models in production. We'll use Baseten as the remote host for your model server.

To set up the Baseten remote, you'll need a [Baseten API key](https://app.baseten.co/settings/account/api_keys).

If you don't have a Baseten account, no worries, just [sign up for an account](https://app.baseten.co/signup/) and you'll be issued plenty of free credits to get you started.
</Accordion>

### Push your Truss

To spin up a model server from your Truss, run:

```sh
truss push
```

Paste your Baseten API key if prompted.

<Tip>
Open up [your model dashboard on Baseten](https://app.baseten.co/models/) to monitor your deployment and view model server logs.
</Tip>

<RequestExample>

```python model/model.py
class Model:
    def __init__(self, **kwargs):
        self._model = None

    def load(self):
        pass

    def predict(self, model_input):
        return model_input
```

```yaml config.yaml
environment_variables: {}
model_name: My First Truss
requirements: []
resources:
  accelerator: null
  cpu: "1"
  memory: 2Gi
  use_gpu: false
secrets: {}
system_packages: []
```

</RequestExample>
