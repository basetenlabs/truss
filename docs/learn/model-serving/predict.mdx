---
title: "Step 3: Invoke the model"
description: "Invoke our deployed \"model\" (aka echo server)."
---

Once your model has finished deploying, you can call it from your terminal.

### Run model invocation

Model input must be JSON-serializable. For our echo server, we'll just send a basic string.

<Note>
Note the double quotes to make the data parameter a string.
</Note>

**Invocation**

```sh
truss predict -d '"I am happy!"'
```

**Response**

```json
"I am happy!"
```

Our model server is up and running. We can push to it and run model inference. In the next step, we'll set up the last piece of the developer loop on Truss.

<RequestExample>

```python model/model.py
from typing import Any


class Model:
    def __init__(self, **kwargs) -> None:
        self._data_dir = kwargs["data_dir"]
        self._config = kwargs["config"]
        self._secrets = kwargs["secrets"]
        self._model = None

    def load(self):
        # Load model here and assign to self._model.
        pass

    def predict(self, model_input: Any) -> Any:
        return model_input
```

<Snippet file="base-config.mdx" />

</RequestExample>
