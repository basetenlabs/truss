---
title: "Step 1: Echo server"
description: "Implement a simple echo server."
---

You don't need an ML model to learn the core dev loop when working with Truss. Instead, we'll write a quick echo server, which simply echos your input back to you.

This step introduces the `my-truss/model/model.py` file. This is one of two essential files in a Truss. In this file, you implement the `Model` class, which the model server runs.

### Implement the echo server

The `Model.predict()` function runs every time the model server endpoint is called.

<Tip>
Check the "Diff" tab to see exactly which lines of code change in each step.
</Tip>

Open `model/model.py` and update `predict()` to echo the `model_input`:

<Tabs>
<Tab title="Code">
```python model/model.py
def predict(self, model_input: Any) -> Any:
    return model_input
```
</Tab>
<Tab title="Diff">
```diff model/model.py
def predict(self, model_input: Any) -> Any:
-    model_output = {}
-    # Invoke model on model_input and calculate predictions here.
-    model_output["predictions"] = []
-    return model_output
+    return model_input
```
</Tab>
</Tabs>

That's all the code for this step! Next, we'll deploy this echo server.

<RequestExample>

```python model/model.py  ●
from typing import Any


class Model:
    def __init__(self, **kwargs) -> None:
        self._data_dir = kwargs["data_dir"]
        self._config = kwargs["config"]
        self._secrets = kwargs["secrets"]
        self._model = None

    def load(self):
        # Load model here and assign to self._model.
        pass

    def predict(self, model_input: Any) -> Any:
        return model_input
```

<Snippet file="base-config.mdx" />

</RequestExample>
