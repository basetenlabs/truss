---
title: "Step 6: Run inference"
description: "Description"
---

In this step, we'll implement invocation for our new ML model.


We'll call the model in `predict()` and return the results:

<Tabs>
<Tab title="Code">
```python model/model.py
def predict(self, model_input: Any) -> Any:
    return self._model(model_input)
```
</Tab>
<Tab title="Diff">
```diff model/model.py
def predict(self, model_input: Any) -> Any:
-    return model_input
+    return self._model(model_input)
```
</Tab>
</Tabs>

<RequestExample>

```python model/model.py  â—
from typing import Any
from transformers import pipeline


class Model:
    def __init__(self, **kwargs) -> None:
        self._data_dir = kwargs["data_dir"]
        self._config = kwargs["config"]
        self._secrets = kwargs["secrets"]
        self._model = None

    def load(self):
        self._model = pipeline("text-classification")

    def predict(self, model_input: Any) -> Any:
        return self._model(model_input)
```

<Snippet file="base-config.mdx" />

</RequestExample>