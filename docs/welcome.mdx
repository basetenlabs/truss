---
title: Welcome to Truss
description: "The simplest way to serve AI/ML models in production"
---

## Why Truss?

* **Write once, run anywhere:** Package and test model code, weights, and dependencies with a model server that behaves the same in development and production.
* **Fast developer loop:** Implement your model with fast feedback from a live reload server, and skip Docker and Kubernetes configuration with Truss' done-for-you model serving environment.
* **Support for all Python frameworks**: From `transformers` and `diffusors` to `PyTorch` and `Tensorflow` to `XGBoost` and `sklearn`, Truss supports models created with any framework, even entirely custom models.

See Trusses for popular models including:

* ðŸ§™ [WizardLM](/examples/models/wizardlm)
* ðŸŽ¨ [Stable Diffusion XL](/examples/models/sdxl)
* ðŸ—£ [Whisper](/examples/models/whisper)

and [dozens more examples on GitHub](https://github.com/basetenlabs/truss-examples/).

## Deploy your first model

<CardGroup cols={2}>
  <Card
    title="Quickstart"
    icon="book"
    href="/quickstart"
  >
    Package, deploy, and invoke an ML model in production all in less than five minutes.
  </Card>
  <Card
    title="Truss tutorial"
    icon="books"
    href="/learn/intro"
  >
    Learn model deployment step-by-step from "Hello, World!" to streaming output from an open-source LLM.
  </Card>
</CardGroup>


## Truss contributors

Truss is backed by [Baseten](https://baseten.co) and built in collaboration with ML engineers worldwide. Special thanks to [Stephan Auerhahn](https://github.com/palp) @ [stability.ai](https://stability.ai/) and [Daniel Sarfati](https://github.com/dsarfati) @ [Salad Technologies](https://salad.com/) for their contributions.

We enthusiastically welcome contributions in accordance with our [contributors' guide](/contribute/contributing) and [code of conduct](https://github.com/basetenlabs/truss/blob/main/CODE_OF_CONDUCT.md).
