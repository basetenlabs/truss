---
title: Welcome to Truss Chains (Î²)
description: "Learn what *Truss Chains* is"
---

<Warning>*Chains* is a beta feature and subject to breaking changes.</Warning>

# Table of Contents

* [Introduction](/chains/intro)
* [Getting Started](/chains/getting-started)
* [Chaining Chainlets](/chains/chaining-chainlets)
* [Guide](/chains/guide)
* [Dependencies & Resources](/chains/deps-and-resources)
* [Reference](/chains/full-reference)

Unlock the power of modular ML development with *Truss Chains*.
Seamlessly integrate multiple model components or any compute/data processing steps into a single workflow.
Enjoy rapid development, scalable remote serving on Baseten,
and speed up your work with horizontal scaling and data chunking.


# Features

<CardGroup cols={2}>
  <Card title="Type-safe Remote Calls" icon="square-1">
    Call Chainlets from other Chainlets with ease: code-completion, type-checking, retries, error handling
    data serialization - all included.
  </Card>
  <Card title="Run different computations on different hardware" icon="square-2">
    Configure each Chainlet to run on specific hardware and with its own dependencies.
  </Card>
  <Card title="Local Debug Mode" icon="square-4">
    Local execution, in combination with mocking, facilitates a fast dev loop and better testability.
  </Card>
  <Card title="Pure Python Configuration" icon="square-3">
    Manage all your config right in the code. No more guessing of YAML schemas, no more undetected typos.
  </Card>
</CardGroup>

# Key Concepts

## Chainlet

The basic building block in a Truss Chain: it performs a specific computation. For example, running a
large ML model, but it can also be a simple function that transforms data. Most importantly: a *Chainlet* can
call other *Chainlets* - which will be *remote calls* when deployed.
Each *Chainlet* is intended to be deployed remotely, with potentially multiple replicas and running in its own
environment (e.g. with specific compute hardware, autoscaling and software dependencies).

<img src="/images/audio-transcription-chainlet.png" />

## Chain

A *Chain* is the result of connecting multiple *Chainlets* to perform an overarching task.
Each *Chain* has an *entrypoint* Chainlet to which requests are made by the client.
Internally, the different Chainlets call each other, thereby structuring or distributing the overall computation -
and eventually the *entrypoint* returns the final result back to the client.
You can imagine this like a "flow chart" or "computational graph".

Here's an example of a Chain that takes a large audio file, splits it into smaller chunks, and transcribes each chunk
 *in parallel* to speed up the transcription process - and then aggregates the results.

<img src="/images/audio-transcription-chain.png" />

## How does it work?

See [Technical Background](/chains/getting-started).


Next: [Getting Started](/chains/getting-started) shows you how to create and run a simple chain
