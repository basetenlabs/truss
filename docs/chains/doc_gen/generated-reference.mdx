# API Reference

## *class* `truss_chains.Assets`

Specifies which assets a chainlet can access in the remote deployment.

Model weight caching can be used like this:

```default
import truss_chains as chains
from truss import truss_config

mistral_cache = truss_config.ModelRepo(
  repo_id="mistralai/Mistral-7B-Instruct-v0.2",
  allow_patterns=["*.json", "*.safetensors", ".model"]
  )
chains.Assets(cached=[mistral_cache], ...)
```

See [truss caching guide](https://truss.baseten.co/guides/model-cache#enabling-caching-for-a-model)
for more details on caching.


**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `cached` | *Iterable[ModelRepo]* | One or more `truss_config.ModelRepo` objects. |
| `secret_keys` | *Iterable[str]* | Names of secrets stored on baseten, that the chainlet should have access to. You can manage secrets on baseten [here](https://app.baseten.co/settings/secrets). |


#### get_spec()

Returns parsed and validated assets.

* **Return type:**
  *AssetSpec*

## *class* `truss_chains.ChainletBase`

Base class for all chainlets.

Inheriting from this class adds validations to make sure subclasses adhere to the
chainlet pattern and facilitates remote chainlet deployment.

Refer to [the docs](https://truss.baseten.co/chains/getting-started) and this
[example chainlet](https://github.com/basetenlabs/truss/blob/main/truss-chains/truss_chains/example_chainlet.py)
for more guidance on how to create subclasses.

## *class* `truss_chains.deploy.ChainService`

Handle for a deployed chain.

A `ChainService` is created and returned when using `deploy_remotely`. It
bundles the individual services for each chainlet in the chain, and provides
utilities to query their status, invoke the entrypoint etc.


**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `entrypoint` | *str* | Name of the entrypoint chainlet. |
| `name` | *str* | Name of the chain. |


#### add_service(name, service)

Used to add a chainlet service during the deployment sequence of the chain.


**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `name` | *str* | Chainlet name. |
| `service` | *TrussService* | Service object for the chainlet. |

* **Return type:**
  None

#### *property* entrypoint_fake_json_data *: Any*

Fake JSON example data that matches the entrypoint’s input schema.
This property must be externally populated.

* **Raises:**
  **ValueError** – If fake data was not set.

#### *property* entrypoint_name *: str*

#### *property* get_entrypoint *: TrussService*

Returns the entrypoint’s service handle.

* **Raises:**
  **MissingDependencyError** – If the entrypoint service was not added.

#### get_info()

Queries the statuses of all chainlets in the chain.

* **Returns:**
  List with elements `(name, status, logs_url)` for each chainlet.
* **Return type:**
  list[tuple[str, str, str]]

#### name *: str*

#### run_remote(json)

Invokes the entrypoint with JSON data.

* **Returns:**
  The JSON response.
* **Parameters:**
  **json** (*Dict*)
* **Return type:**
  *Any*

#### *property* run_url *: str*

URL to invoke the entrypoint.

#### *property* services *: MutableMapping[str, TrussService]*

## *class* `truss_chains.ChainsRuntimeError`

Bases: `Exception`

Raised when components are not used the expected way at runtime.

## *class* `truss_chains.Compute`

Specifies which compute resources a chainlet has in the *remote* deployment.

#### NOTE
Not all combinations can be exactly satisfied by available hardware, in some
cases more powerful machine types are chosen to make sure requirements are met or
over-provisioned. Refer to the
[baseten instance reference](https://docs.baseten.co/performance/instances).


**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `cpu_count` | *int* | Minimum number of CPUs to allocate. |
| `memory` | *str* | Minimum memory to allocate, e.g. “2Gi” (2 gibibytes). |
| `gpu` | *str\|Accelerator\|None* | GPU accelerator type, e.g. “A10G”, “A100”, refer to the [truss config](https://truss.baseten.co/reference/config#resources-accelerator) for more choices. |
| `gpu_count` | *int* | Number of GPUs to allocate. |
| `predict_concurrency` | *int\|Literal['cpu_count']* | Number of concurrent requests a single replica of a deployed chainlet handles. |


Concurrency concepts are explained in [this guide](https://truss.baseten.co/guides/concurrency).
It is important to understand the difference between predict_concurrency and
the concurrency target (used for autoscaling, i.e. adding or removing replicas).
Furthermore, the `predict_concurrency` of a single instance is implemented in
two ways:

- Via python’s `asyncio`, if `run_remote` is an async def. This
  requires that `run_remote` yields to the event loop.
- With a threadpool if it’s a synchronous function. This requires
  that the threads don’t have significant CPU load (due to the GIL).

#### get_spec()

* **Return type:**
  *ComputeSpec*

## `truss_chains.depends`

Sets a “symbolic marker” to indicate to the framework that a chainlet is a
dependency of another chainlet. The return value of `depends` is intended to be
used as a default argument in a chainlet’s `__init__`-method.
When deploying a chain remotely, a corresponding stub to the remote is injected in
its place. In `run_local` mode an instance of a local chainlet is injected.

Refer to [the docs](https://truss.baseten.co/chains/getting-started) and this
[example chainlet](https://github.com/basetenlabs/truss/blob/main/truss-chains/truss_chains/example_chainlet.py)
for more guidance on how make one chainlet depend on another chainlet.

#### WARNING
Despite the type annotation, this does *not* immediately provide a
chainlet instance. Only when deploying remotely or using `run_local` a
chainlet instance is provided.


**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `chainlet_cls` | *Type[ChainletT]* | The chainlet class of the dependency. |
| `retries` | *int* | The number of times to retry the remote chainlet in case of failures (e.g. due to transient network issues). |

* **Returns:**
  A “symbolic marker” to be used as a default argument in a chainlet’s
  initializer.
* **Return type:**
  *ChainletT*

## `truss_chains.depends_context`

Sets a “symbolic marker” for injecting a context object at runtime.

Refer to [the docs](https://truss.baseten.co/chains/getting-started) and this
[example chainlet](https://github.com/basetenlabs/truss/blob/main/truss-chains/truss_chains/example_chainlet.py)
for more guidance on the `__init__`-signature of chainlets.

#### WARNING
Despite the type annotation, this does *not* immediately provide a
context instance. Only when deploying remotely or using `run_local` a
context instance is provided.

* **Returns:**
  A “symbolic marker” to be used as a default argument in a chainlet’s
  initializer.
* **Return type:**
  [*DeploymentContext*](#truss_chains.DeploymentContext)

## `truss_chains.deploy_remotely`

Deploys a chain remotely (with all dependent chainlets).


**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `entrypoint` | *Type[ABCChainlet]* | The chainlet class that serves as the entrypoint to the chain. |
| `chain_name` | *str* | The name of the chain. |
| `publish` | *bool* | Whether to publish the chain as a published deployment (it is a draft deployment otherwise) |
| `promote` | *bool* | Whether to promote the chain to be the production deployment (this implies publishing as well). |
| `only_generate_trusses` | *bool* | Used for debugging purposes. If set to True, only the the underlying truss models for the chainlets are generated in `/tmp/.chains_generated`. |

* **Returns:**
  A chain service handle to the deployed chain.
* **Return type:**
  [*ChainService*](#truss_chains.deploy.ChainService)

## *class* `truss_chains.DeploymentContext`

Bases: `pydantic.BaseModel`, `Generic`[`UserConfigT`]

Bundles config values and resources needed to instantiate Chainlets.

This is provided at runtime to the Chainlet’s `__init__` method.


**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `data_dir` | *Path\|None* | The directory where the chainlet can store and access data, e.g. for downloading model weights. |
| `user_config` | *UserConfigT* | User-defined configuration for the chainlet. |
| `chainlet_to_service` | *Mapping[str,[ServiceDescriptor](#truss_chains.ServiceDescriptor* | A mapping from chainlet names to service descriptors. This is used create RPCs sessions to dependency chainlets. It contains only the chainlet services that are dependencies of the current chainlet. |
| `secrets` | *MappingNoIter[str,str]* | A mapping from secret names to secret values. It contains only the secrets that are listed in `remote_config.assets.secret_keys` of the current chainlet. |

#### chainlet_to_service *: Mapping[str, [ServiceDescriptor](#truss_chains.ServiceDescriptor)]*

#### data_dir *: Path | None*

#### get_baseten_api_key()

* **Return type:**
  str

#### get_service_descriptor(chainlet_name)

* **Parameters:**
  **chainlet_name** (*str*)
* **Return type:**
  [*ServiceDescriptor*](#truss_chains.ServiceDescriptor)

#### secrets *: MappingNoIter[str, str]*

#### user_config *: UserConfigT*

## *class* `truss_chains.DockerImage`

Bases: `pydantic.BaseModel`

Configures the docker image in which a remoted chainlet is deployed.

#### NOTE
Any paths are relative to the source file where `DockerImage` is
defined and must be created with the helper function `make_abs_path_here`.
This allows you for example organize chainlets in different (potentially nested)
modules and keep their requirement files right next their python source files.


**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `base_image` | *str* | The base image to use for the chainlet. Default is `python:3.11-slim`. |
| `pip_requirements_file` | *AbsPath\|None* | Path to a file containing pip requirements. The file content is naively concatenated with `pip_requirements`. |
| `pip_requirements` | *list[str]* | A list of pip requirements to install.  The items are naively concatenated with the content of the `pip_requirements_file`. |
| `apt_requirements` | *list[str]* | A list of apt requirements to install. |
| `data_dir` | *AbsPath\|None* | Data from this directory is copied into the docker image and accessible to the remote chainlet at runtime. |
| `external_package_dirs` | *list[AbsPath]\|None* | A list of directories containing additional python packages outside the chain’s workspace dir, e.g. a shared library. This code is copied into the docker image and importable at runtime. |

#### apt_requirements *: list[str]*

#### base_image *: str*

#### data_dir *: AbsPath | None*

#### external_package_dirs *: list[AbsPath] | None*

#### pip_requirements *: list[str]*

#### pip_requirements_file *: AbsPath | None*

## `truss_chains.make_abs_path_here`

Helper to specify file paths relative to the *immediately calling* module.

E.g. in you have a project structure like this:

```default
root/
    chain.py
    common_requirements.text
    sub_package/
        chainlet.py
        chainlet_requirements.txt
```

You can now in `root/sub_package/chainlet.py` point to the requirements
file like this:

```default
shared = RelativePathToHere("../common_requirements.text")
specific = RelativePathToHere("chainlet_requirements.text")
```

#### WARNING
This helper uses the directory of the immediately calling module as an
absolute reference point for resolving the file location. Therefore,
you MUST NOT wrap the instantiation of `make_abs_path_here` into a
function (e.g. applying decorators) or use dynamic code execution.

Ok:

```default
def foo(path: AbsPath):
    abs_path = path.abs_path

foo(make_abs_path_here("./somewhere"))
```

Not Ok:

```default
def foo(path: str):
    dangerous_value = make_abs_path_here(path).abs_path

foo("./somewhere")
```

* **Parameters:**
  **file_path** (*str*)
* **Return type:**
  *AbsPath*

## `truss_chains.mark_entrypoint`

Decorator to mark a chainlet as the entrypoint of a chain.

This decorator can be applied to *one* chainlet in a source file and then the
CLI deploy command simplifies because only the file, but not the chainlet class
in the file needs to be specified.

Example usage:

```default
import truss_chains as chains

@chains.mark_entrypoint
class MyChainlet(ChainletBase):
    ...
```

* **Parameters:**
  **cls** (*Type* *[**ChainletT* *]*)
* **Return type:**
  *Type*[*ChainletT*]

## *class* `truss_chains.RemoteConfig`

Bases: `pydantic.BaseModel`

Bundles config values needed to deploy a chainlet remotely..

This is specified as a class variable for each chainlet class, e.g.:

```default
import truss_chains as chains


class MyChainlet(chains.ChainletBase):
    remote_config = chains.RemoteConfig(
        docker_image=chains.DockerImage(
            pip_requirements=["torch==2.0.1", ... ]
        ),
        compute=chains.Compute(cpu_count=2, gpu="A10G", ...),
        assets=chains.Assets(secret_keys=["hf_access_token"], ...),
    )
```

**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `docker_image` | *[DockerImage](#truss_chains.DockerImage* |  |
| `compute` | *[Compute](#truss_chains.Compute* |  |
| `assets` | *[Assets](#truss_chains.Assets* |  |
| `name` | *str\|None* |  |


#### assets *: [Assets](#truss_chains.Assets)*

#### compute *: [Compute](#truss_chains.Compute)*

#### docker_image *: [DockerImage](#truss_chains.DockerImage)*

#### get_asset_spec()

* **Return type:**
  *AssetSpec*

#### get_compute_spec()

* **Return type:**
  *ComputeSpec*

#### name *: str | None*

## *class* `truss_chains.RemoteErrorDetail`

Bases: `pydantic.BaseModel`

When a remote chainlet raises an exception, this pydantic model contains
information about the error and stack trace and is included in JSON form in the
error response.

**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `remote_name` | *str* |  |
| `exception_cls_name` | *str* |  |
| `exception_module_name` | *str\|None* |  |
| `exception_message` | *str* |  |
| `user_stack_trace` | *list[StackFrame]* |  |


#### exception_cls_name *: str*

#### exception_message *: str*

#### exception_module_name *: str | None*

#### format()

Format the error for printing, similar to how Python formats exceptions
with stack traces.

* **Return type:**
  str

#### remote_name *: str*

#### user_stack_trace *: list[StackFrame]*

## *class* `truss_chains.RPCOptions`

Bases: `pydantic.BaseModel`

Options to customize RPCs to dependency chainlets.

**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `timeout_sec` | *int* |  |
| `retries` | *int* |  |


#### retries *: int*

#### timeout_sec *: int*

## `truss_chains.run_local`

Context manager local debug execution of a chain.

The arguments only need to be provided if the chainlets explicitly access any the
corresponding fields of `DeploymentContext`.


**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `secrets` | *Mapping[str,str]\|None* | A dict of secrets keys and values to provide to the chainlets. |
| `data_dir` | *Path\|str\|None* | Path to a directory with data files. |
| `chainlet_to_service` | *Mapping[str,[ServiceDescriptor](#truss_chains.ServiceDescriptor* | A dict of chainlet names to service descriptors. |

* **Return type:**
  *ContextManager*[None]

Example usage (as trailing main section in a chain file):

```default
import os
import truss_chains as chains


class HelloWorld(chains.ChainletBase):
  ...


if __name__ == "__main__":
    with chains.run_local(
        secrets={"some_token": os.environ["SOME_TOKEN"]},
        chainlet_to_service={
            "SomeChainlet": chains.ServiceDescriptor(
                name="SomeChainlet",
                predict_url="https://...",
                options=chains.RPCOptions(),
            )
        },
    ):
        hello_world_chain = HelloWorld()
        result = hello_world_chain.run_remote(max_value=5)

    print(result)
```

Refer to the [local debugging guide](https://truss.baseten.co/chains/guide#local-debugging)
for more details.

## *class* `truss_chains.ServiceDescriptor`

Bases: `pydantic.BaseModel`

Bundles values to establish an RPC session to a dependency chainlet,
specifically with `StubBase`.

**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `name` | *str* |  |
| `predict_url` | *str* |  |
| `options` | *[RPCOptions](#truss_chains.RPCOptions* |  |


#### name *: str*

#### options *: [RPCOptions](#truss_chains.RPCOptions)*

#### predict_url *: str*

## *class* `truss_chains.StubBase`

Bases: `ABC`

Base class for stubs that invoke remote chainlets.

It is used internally for RPCs to dependency chainlets, but it can also be used
in user-code for wrapping a deployed truss model into the chains framework, e.g.
like that:

```default
import pydantic
import truss_chains as chains

class WhisperOutput(pydantic.BaseModel):
  ...


class DeployedWhisper(chains.StubBase):

    async def run_remote(self, audio_b64: str) -&gt; WhisperOutput:
        resp = await self._remote.predict_async(json_payload={"audio": audio_b64})
        return WhisperOutput(text=resp["text"], language==resp["language"])


class MyChainlet(chains.ChainletBase):

   def __init__(self, ..., context = chains.depends_context()):
       ...
       self._whisper = DeployedWhisper.from_url(
        WHISPER_URL,
        context,
        options=chains.RPCOptions(retries=3),
    )
```


**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `service_descriptor` | *[ServiceDescriptor](#truss_chains.ServiceDescriptor* | Contains the URL and other configuration. |
| `api_key` | *str* | A baseten API key to authorize requests. |


#### *classmethod* from_url(predict_url, context, options=None)

Factory method, convenient to be used in chainlet’s `__init__`-method.


**Parameters:**

| Name | Type | Description |
|------|------|-------------|
| `predict_url` | *str* | URL to predict endpoint of another chain / truss model. |
| `context` | *[DeploymentContext](#truss_chains.DeploymentContext* | Deployment context object, obtained in the chainlet’s `__init__`. |
| `options` | *[RPCOptions](#truss_chains.RPCOptions* | RPC options, e.g. retries. |
