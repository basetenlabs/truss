server {
    # We use the proxy_read_timeout directive here (instead of proxy_send_timeout) as it sets the timeout for reading a response from the proxied server vs. setting a timeout for sending a request to the proxied server.
    listen 8080;
    client_max_body_size {{client_max_body_size}};
    proxy_buffering off;
    proxy_set_header Connection "";

    # Liveness endpoint override
    location = / {
        proxy_redirect off;
        proxy_read_timeout 300s;

        rewrite ^/$ {{liveness_endpoint}} break;

        proxy_pass http://127.0.0.1:{{server_port}};
    }
    # Readiness endpoint override
    location ~ ^/v1/models/model$ {
        proxy_redirect off;
        proxy_read_timeout 300s;

        rewrite ^/v1/models/model$ {{readiness_endpoint}} break;

        proxy_pass http://127.0.0.1:{{server_port}};
    }
    # Predict
    location ~ ^/v1/models/model:predict$ {
        proxy_redirect off;
        proxy_read_timeout 300s;

        rewrite ^/v1/models/model:predict$ {{server_endpoint}} break;

        proxy_pass http://127.0.0.1:{{server_port}};
    }

    # Forward all other paths
    location / {
        proxy_redirect off;
        proxy_read_timeout 300s;

        proxy_pass http://127.0.0.1:{{server_port}};
    }

}
