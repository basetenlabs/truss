build:
  arguments:
    endpoint: Completions
    model: gs://llama-2-7b
    tokenizer: hf-internal-testing/llama-tokenizer
  model_server: VLLM
environment_variables: {}
external_package_dirs: []
model_metadata: {}
model_name: vllm llama gcs
python_version: py39
requirements: []
resources:
  accelerator: A10G
  cpu: 500m
  memory: 30Gi
  use_gpu: true
secrets: {}
system_packages: []
